{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rocket League Notebook 4: Feature Engineering\n",
    "\n",
    "## Goals \n",
    "\n",
    "- Create models using engineered features\n",
    "\n",
    "## Results\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = { 'bronze': 1, 'silver': 2, 'gold': 3, 'platinum': 4, 'diamond': 5, 'champion': 6 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lowbound = Q1-1.5*IQR\n",
    "    highbound = Q3+1.5*IQR\n",
    "    df_bounded = df[(df[col] >= lowbound) & (df[col] <= highbound)]\n",
    "\n",
    "    return df_bounded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create columns for model\n",
    "\n",
    "Also include\n",
    "\n",
    "    - duration\n",
    "    - percent_supersonic_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_plus = matches.assign(\n",
    "            score_per_second = lambda x: x['score']/x['duration'],\n",
    "            lowvhigh = lambda x: x['percent_low_air']/x['percent_high_air'],\n",
    "            percent_boost_50_100 = lambda x: x['percent_boost_50_75']+x['percent_boost_75_100'],\n",
    "            goals_saves_pm = lambda x: (x['goals']+x['saves'])*60/x['duration'],\n",
    "            save_prop = lambda x: x['saves']/x['shots_against']\n",
    "    ).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54213, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = ['duration',\n",
    "            'percent_supersonic_speed',\n",
    "            'score_per_second',\n",
    "            'lowvhigh',\n",
    "            'percent_boost_50_100',\n",
    "            'goals_saves_pm',\n",
    "            'save_prop'\n",
    "            ]\n",
    "\n",
    "matches_prepped = matches_plus[['rank']+variables].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "for var in variables:\n",
    "\n",
    "    matches_prepped = filter_outliers(matches_prepped, var)\n",
    "\n",
    "matches_prepped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END ......................................logreg__C=100; total time=   0.7s\n",
      "[CV] END ......................................logreg__C=100; total time=   0.7s\n",
      "[CV] END ......................................logreg__C=100; total time=   0.7s\n",
      "[CV] END ......................................logreg__C=100; total time=   0.9s\n",
      "[CV] END ......................................logreg__C=100; total time=   0.9s\n",
      "[CV] END .......................................logreg__C=10; total time=   0.7s\n",
      "[CV] END .......................................logreg__C=10; total time=   0.7s\n",
      "[CV] END .......................................logreg__C=10; total time=   0.7s\n",
      "[CV] END .......................................logreg__C=10; total time=   0.9s\n",
      "[CV] END .......................................logreg__C=10; total time=   1.1s\n",
      "[CV] END ......................................logreg__C=1.0; total time=   0.7s\n",
      "[CV] END ......................................logreg__C=1.0; total time=   0.7s\n",
      "[CV] END ......................................logreg__C=1.0; total time=   0.8s\n",
      "[CV] END ......................................logreg__C=1.0; total time=   1.2s\n",
      "[CV] END ......................................logreg__C=1.0; total time=   1.2s\n",
      "[CV] END ......................................logreg__C=0.1; total time=   1.0s\n",
      "[CV] END ......................................logreg__C=0.1; total time=   1.0s\n",
      "[CV] END ......................................logreg__C=0.1; total time=   0.9s\n",
      "[CV] END ......................................logreg__C=0.1; total time=   1.1s\n",
      "[CV] END ......................................logreg__C=0.1; total time=   1.2s\n",
      "[CV] END .....................................logreg__C=0.01; total time=   0.8s\n",
      "[CV] END .....................................logreg__C=0.01; total time=   0.8s\n",
      "[CV] END .....................................logreg__C=0.01; total time=   0.7s\n",
      "[CV] END .....................................logreg__C=0.01; total time=   0.8s\n",
      "[CV] END .....................................logreg__C=0.01; total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('logreg', LogisticRegression())]),\n",
       "             param_grid={'logreg__C': [100, 10, 1.0, 0.1, 0.01]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = matches_prepped[variables]\n",
    "y = matches_prepped['rank']\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, random_state=42, stratify = y)\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "param_grid = {'logreg__C':[100, 10, 1.0, 0.1, 0.01]}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid, scoring = 'accuracy', verbose = 2)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.39272539471742657\n",
      "Confusion Matrix: \n",
      " [[   0    3    3  128   30   97]\n",
      " [   0 1473  734   50  420    1]\n",
      " [   0  938  980  295  951   10]\n",
      " [   0   95  332 1299  938  144]\n",
      " [   0  345  722  918 1384   38]\n",
      " [   0   15   56  722  246  187]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrior\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jrior\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      bronze       0.00      0.00      0.00       261\n",
      "    champion       0.51      0.55      0.53      2678\n",
      "     diamond       0.35      0.31      0.33      3174\n",
      "        gold       0.38      0.46      0.42      2808\n",
      "    platinum       0.35      0.41      0.38      3407\n",
      "      silver       0.39      0.15      0.22      1226\n",
      "\n",
      "    accuracy                           0.39     13554\n",
      "   macro avg       0.33      0.31      0.31     13554\n",
      "weighted avg       0.38      0.39      0.38     13554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrior\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91809cd6930bcd5c93f1baaa8e75dc4fbfa15bbd921b33b01843a7cf2fa05e32"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
